{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import SVG, Markdown, display, display_pretty\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Results/results_experiments_hyperparameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "df[df['Latent Space']==10].sort_values(['domain_BrayCurtis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "group_columns = ['Input transform', 'Output transform', 'Reconstruction Loss', 'Latent Space',\n",
    "                 'Bioma Autoencoder', 'Domain Autoencoder', 'Activation Encoder',\n",
    "                 'Activation Decoder', 'Activation Latent',\n",
    "                 'Batch Size', 'Learning Rate', 'Optimizer']\n",
    "metrics_columns = ['domain_mse', 'domain_mae', 'domain_mape', 'domain_BrayCurtis',\n",
    "                   'domain_pearson_corr', 'domain_jensen_shannon_divergence']\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Mean validation results averaging by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[group_columns[0:3] + metrics_columns].groupby(group_columns[0:3]).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[3]] + metrics_columns].groupby(group_columns[3]).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[4]] + metrics_columns].groupby(group_columns[4]).mean().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[5]] + metrics_columns].groupby(group_columns[5]).mean().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[6]] + metrics_columns].groupby(group_columns[6]).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[7]] + metrics_columns].groupby(group_columns[7]).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[8]] + metrics_columns].groupby(group_columns[8]).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[group_columns[9]] + metrics_columns].groupby(group_columns[9]).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[group_columns[10:12] + metrics_columns].groupby(group_columns[10:12]).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Best experiment per metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics_columns[0], df[metrics_columns[0]].min())\n",
    "\n",
    "df[df[metrics_columns[0]] == df[metrics_columns[0]].min()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics_columns[1], df[metrics_columns[1]].min())\n",
    "\n",
    "df[df[metrics_columns[1]] == df[metrics_columns[1]].min()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics_columns[2], df[metrics_columns[2]].min())\n",
    "\n",
    "df[df[metrics_columns[2]] == df[metrics_columns[2]].min()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics_columns[3], df[metrics_columns[3]].min())\n",
    "\n",
    "df[df[metrics_columns[3]] == df[metrics_columns[3]].min()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics_columns[4], df[metrics_columns[4]].max())\n",
    "\n",
    "df[df[metrics_columns[4]] == df[metrics_columns[4]].max()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(metrics_columns[5], df[metrics_columns[5]].min())\n",
    "\n",
    "df[df[metrics_columns[5]] == df[metrics_columns[5]].min()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "- There is not too much diference among the activation functions\n",
    "- Center log ratio and percentage works similary, none transformation works much worse (see how graph evolves)\n",
    "- The bigger the latent space the better although there is not too much difference between 50 and 100\n",
    "- Smaller autoencoder work better in general but we got the best results with bigger autoencoders (more layers, more nodes per layer)\n",
    "- batch size 64 with lr of 0.001 works better than batch size of 128 with lr 0.01. Probably because the small dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
