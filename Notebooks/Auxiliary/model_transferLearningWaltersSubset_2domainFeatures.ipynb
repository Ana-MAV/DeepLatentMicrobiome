{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning subset Walters et al.: 2 domain features\n",
    "## Table of contents \n",
    "1. [Linear Regression](#LinearRegression)\n",
    "2. [MLP (Dense)](#MLP)\n",
    "3. [AE combined latent subset features](#AE_combined_subsetFeatures)\n",
    "4. [AE combined latent all features](#AE_combined_allFeatures)\n",
    "5. [AE OTU latent](#AE_latentOTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Src/')\n",
    "from data import *\n",
    "from train_2 import *\n",
    "from transfer_learning import *\n",
    "from test_functions import *\n",
    "from layers import *\n",
    "from utils import *\n",
    "from loss import *\n",
    "from metric import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbioma_train, df_microbioma_test, \\\n",
    "df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, \\\n",
    "df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test,\\\n",
    "otu_columns, domain_columns = \\\n",
    "    read_df_with_transfer_learning_subset_fewerDomainFeatures( \\\n",
    "        metadata_names=['Temperature','Precipitation3Days'], \\\n",
    "        otu_filename='../../Datasets/otu_table_all_80.csv', \\\n",
    "        metadata_filename='../../Datasets/metadata_table_all_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_domain_train.shape)\n",
    "print(df_domain_test.shape)\n",
    "print(df_domain_transfer_learning_train.shape)\n",
    "print(df_domain_transfer_learning_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN:')\n",
    "print('rain:' + str(df_domain_transfer_learning_train.loc[:,'Precipitation3Days'].mean()))\n",
    "print('Tª:' + str(df_domain_transfer_learning_train.loc[:,'Temperature'].mean()))\n",
    "    \n",
    "print('TEST:')\n",
    "print('rain:' + str(df_domain_transfer_learning_test.loc[:,'Precipitation3Days'].mean()))\n",
    "print('Tª:' + str(df_domain_transfer_learning_test.loc[:,'Temperature'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get numpy transfer_learning objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_microbioma_transfer_learning_train = df_microbioma_transfer_learning_train.to_numpy(dtype=np.float32)\n",
    "data_microbioma_transfer_learning_test = df_microbioma_transfer_learning_test.to_numpy(dtype=np.float32)\n",
    "data_domain_transfer_learning_train = df_domain_transfer_learning_train.to_numpy(dtype=np.float32)\n",
    "data_domain_transfer_learning_test = df_domain_transfer_learning_test.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear regression <a name=\"LinearRegression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(shape_in, shape_out, output_transform):\n",
    "    in_layer = layers.Input(shape=(shape_in,))\n",
    "    net = in_layer\n",
    "    net = layers.Dense(shape_out, activation='linear')(net)\n",
    "    if output_transform is not None:\n",
    "        net = output_transform(net)\n",
    "    out_layer = net\n",
    "    \n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    return model\n",
    "\n",
    "def compile_model(model, optimizer, reconstruction_error, input_transform, output_transform):\n",
    "    metrics = get_experiment_metrics(input_transform, output_transform)[0][3:]\n",
    "    model.compile(optimizer=optimizer, loss=reconstruction_error, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    m = model(shape_in=2,\n",
    "              shape_out=717,\n",
    "              output_transform=None)\n",
    "    \n",
    "    compile_model(model=m,\n",
    "                  optimizer=optimizers.Adam(lr=0.001),\n",
    "                  reconstruction_error=LossMeanSquaredErrorWrapper(CenterLogRatio(), None),\n",
    "                  input_transform=CenterLogRatio(),\n",
    "                  output_transform=None)\n",
    "    return m, None, m, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = 0\n",
    "results, modelsLR = train(model_fn,\n",
    "                        data_microbioma_transfer_learning_train,\n",
    "                        data_domain_transfer_learning_train,\n",
    "                        latent_space=latent_space,\n",
    "                        folds=5,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        learning_rate_scheduler=None,\n",
    "                        verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_model(modelsLR, CenterLogRatio, None, otu_columns, data_microbioma_transfer_learning_test, data_domain_transfer_learning_test)\n",
    "#save_predictions(predictions, 'experiment_transfer_learning_WaltersSubset_linear_regresion.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MLP (Dense) <a name=\"MLP\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(shape_in, shape_out, output_transform, layers_list, activation_fn):\n",
    "    in_layer = layers.Input(shape=(shape_in,))\n",
    "    net = in_layer\n",
    "    for s in layers_list:\n",
    "        net = layers.Dense(s, activation=activation_fn)(net)\n",
    "    net = layers.Dense(shape_out, activation='linear')(net)\n",
    "    if output_transform is not None:\n",
    "        net = output_transform(net)\n",
    "    out_layer = net\n",
    "    \n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    return model\n",
    "\n",
    "def compile_model(model, optimizer, reconstruction_error, input_transform, output_transform):\n",
    "    metrics = get_experiment_metrics(input_transform, output_transform)[0][3:]\n",
    "    model.compile(optimizer=optimizer, loss=reconstruction_error, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    m = model(shape_in=2,\n",
    "              shape_out=717,\n",
    "              output_transform=None,\n",
    "              layers_list=[128,512],\n",
    "              activation_fn='tanh')\n",
    "    \n",
    "    compile_model(model=m,\n",
    "                  optimizer=optimizers.Adam(lr=0.01),\n",
    "                  reconstruction_error=LossMeanSquaredErrorWrapper(CenterLogRatio(), None),\n",
    "                  input_transform=CenterLogRatio(),\n",
    "                  output_transform=None)\n",
    "    return m, None, m, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space=0\n",
    "results, modelsMLP = train(model_fn,\n",
    "                        data_microbioma_transfer_learning_train,\n",
    "                        data_domain_transfer_learning_train,\n",
    "                        latent_space=latent_space,\n",
    "                        folds=5,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        learning_rate_scheduler=None,\n",
    "                        verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_model(modelsMLP, CenterLogRatio, None, otu_columns, data_microbioma_transfer_learning_test, data_domain_transfer_learning_test)\n",
    "#save_predictions(predictions, 'experiment_transfer_learning_WaltersSubset_MLP.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auto-encoder combined latent subset features <a name=\"AE_combined_subsetFeatures\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get numpy train objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_domain_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create auto-encoder combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the selected model (the best one from those with the smallest latent space (10)): no.351\n",
    "experiment_metrics, models, results = perform_experiment_2(cv_folds=0, \n",
    "                        epochs=100, \n",
    "                        batch_size=64, \n",
    "                        learning_rate=0.001, \n",
    "                        optimizer=optimizers.Adam,\n",
    "                        learning_rate_scheduler=None,\n",
    "                        input_transform=Percentage,\n",
    "                        output_transform=tf.keras.layers.Softmax,\n",
    "                        reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None), \n",
    "                        latent_space=10, \n",
    "                        layers=[512,256],\n",
    "                        activation='tanh', \n",
    "                        activation_latent='tanh', \n",
    "                        data_microbioma_train=data_microbioma_train,\n",
    "                        data_domain_train=data_domain_train,\n",
    "                        show_results=True, \n",
    "                        device='/CPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get encoders and decoders to use in transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder, encoder_domain, decoder = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict latent space for samples in transfer learning Walters et al. subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_transfer_learning_train = encoder.predict(data_microbioma_transfer_learning_train)\n",
    "latent_transfer_learning_test = encoder.predict(data_microbioma_transfer_learning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build model to predict latent space \n",
    "Dense model, with transfer_learning_train. With input=domain, output=10 neurons latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_tl():\n",
    "    in_layer = layers.Input(shape=(2,))\n",
    "    net = layers.Dense(64, activation='tanh')(in_layer)\n",
    "    net = layers.Dense(32, activation='tanh')(net)\n",
    "    net = layers.Dense(16, activation='tanh')(net)\n",
    "    out_layer = layers.Dense(latent_transfer_learning_train.shape[1], activation=None)(net) # 'tanh already'\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tl, model_tl = train_tl_noEnsemble(model_fn_tl,\n",
    "                            latent_transfer_learning_train,\n",
    "                            latent_transfer_learning_train,\n",
    "                            data_domain_transfer_learning_train,\n",
    "                            data_domain_transfer_learning_train,\n",
    "                            epochs=100,\n",
    "                            batch_size=16,\n",
    "                            verbose=-1)\n",
    "#print_results(result_tl)\n",
    "#print(result_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test only Dense(domain->latent)\n",
    "predictions = test_model_tl_latent(model_tl, latent_transfer_learning_test, data_domain_transfer_learning_test)\n",
    "#save_predictions(predictions, 'experiment_transfer_learning_WaltersSubset_MLP_domain-latent_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Domain -> latent -> microbiome. Test set TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = test_model_tl_noEnsemble(model_tl, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_transfer_learning_test, data_domain_transfer_learning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) With the encoder_domain (best case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with encoder_biome, en vez de model_tl\n",
    "predictions = test_model_tl_noEnsemble(encoder_domain, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_transfer_learning_test, data_domain_transfer_learning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Auto-encoder combined latent All features <a name=\"AE_combined_allFeatures\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get datasets with ALL domain features and numpy train objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbioma_train, df_microbioma_test, \\\n",
    "_, _, df_domain_train, df_domain_test, _, _,\\\n",
    "otu_columns, domain_columns = \\\n",
    "    read_df_with_transfer_learning_subset( \\\n",
    "        otu_filename='../../Datasets/otu_table_all_80.csv', \\\n",
    "        metadata_filename='../../Datasets/metadata_table_all_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)\n",
    "data_domain_train = df_domain_train.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_domain_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the selected model (the best one from those with the smallest latent space (10)): no.351\n",
    "experiment_metrics, models, results = perform_experiment_2(cv_folds=0, \n",
    "                        epochs=100, \n",
    "                        batch_size=64, \n",
    "                        learning_rate=0.001, \n",
    "                        optimizer=optimizers.Adam,\n",
    "                        learning_rate_scheduler=None,\n",
    "                        input_transform=Percentage,\n",
    "                        output_transform=tf.keras.layers.Softmax,\n",
    "                        reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None), \n",
    "                        latent_space=10, \n",
    "                        layers=[512,256],\n",
    "                        activation='tanh', \n",
    "                        activation_latent='tanh',\n",
    "                        data_microbioma_train=data_microbioma_train,\n",
    "                        data_domain_train=data_domain_train,                                                            \n",
    "                        show_results=True, \n",
    "                        device='/CPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_domain_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get encoders and decoders to use in transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder, encoder_domain, decoder = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To recover data with subset domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbioma_train, df_microbioma_test, \\\n",
    "df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, \\\n",
    "df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test,\\\n",
    "otu_columns, domain_columns = \\\n",
    "    read_df_with_transfer_learning_subset_fewerDomainFeatures( \\\n",
    "        metadata_names=['Temperature','Precipitation3Days'], \\\n",
    "        otu_filename='../../Datasets/otu_table_all_80.csv', \\\n",
    "        metadata_filename='../../Datasets/metadata_table_all_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domain_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict latent space for samples in transfer learning Walters et al. subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_transfer_learning_train = encoder.predict(data_microbioma_transfer_learning_train)\n",
    "latent_transfer_learning_test = encoder.predict(data_microbioma_transfer_learning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build model to predict latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_tl():\n",
    "    in_layer = layers.Input(shape=(2,))\n",
    "    net = layers.Dense(64, activation='tanh')(in_layer)\n",
    "    net = layers.Dense(32, activation='tanh')(net)\n",
    "    net = layers.Dense(16, activation='tanh')(net)\n",
    "    out_layer = layers.Dense(latent_transfer_learning_train.shape[1], activation=None)(net) # 'tanh already'\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tl, model_tl = train_tl_noEnsemble(model_fn_tl,\n",
    "                            latent_transfer_learning_train,\n",
    "                            latent_transfer_learning_train,\n",
    "                            data_domain_transfer_learning_train,\n",
    "                            data_domain_transfer_learning_train,\n",
    "                            epochs=100,\n",
    "                            batch_size=16,\n",
    "                            verbose=-1)\n",
    "#print_results(result_tl)\n",
    "#print(result_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test only Dense(domain->latent)\n",
    "predictions = test_model_tl_latent(model_tl, latent_transfer_learning_test, data_domain_transfer_learning_test)\n",
    "#save_predictions(predictions, 'experiment_transfer_learning_WaltersSubset_MLP_domain-latent_test.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain -> latent -> microbiome. Test set TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = test_model_tl_noEnsemble(model_tl, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_transfer_learning_test, data_domain_transfer_learning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Auto-encoder OTU latent <a name=\"AE_latentOTU\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get microbioma train data and numpy train objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbioma_train, df_microbioma_test, \\\n",
    "df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, \\\n",
    "df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test,\\\n",
    "otu_columns, domain_columns = \\\n",
    "    read_df_with_transfer_learning_subset( \\\n",
    "        otu_filename='../../Datasets/otu_table_all_80.csv', \\\n",
    "        metadata_filename='../../Datasets/metadata_table_all_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_microbioma_train = df_microbioma_train.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_microbioma_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the selected model (the best one from those with the smallest latent space (10)): no.351\n",
    "experiment_metrics, models, results = perform_experiment_2(cv_folds=0, \n",
    "                        epochs=100, \n",
    "                        batch_size=64, \n",
    "                        learning_rate=0.001, \n",
    "                        optimizer=optimizers.Adam,\n",
    "                        learning_rate_scheduler=None,\n",
    "                        input_transform=Percentage,\n",
    "                        output_transform=tf.keras.layers.Softmax,\n",
    "                        reconstruction_loss=MakeLoss(LossBrayCurtis, Percentage, None), \n",
    "                        latent_space=10, \n",
    "                        layers=[512,256],\n",
    "                        activation='tanh', \n",
    "                        activation_latent='tanh', \n",
    "                        data_microbioma_train=data_microbioma_train,\n",
    "                        data_domain_train=None,\n",
    "                        show_results=True, \n",
    "                        device='/CPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get encoders and decoders to use in transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder, _ ,decoder = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To recover data with subset domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbioma_train, df_microbioma_test, \\\n",
    "df_microbioma_transfer_learning_train, df_microbioma_transfer_learning_test, \\\n",
    "df_domain_train, df_domain_test, df_domain_transfer_learning_train, df_domain_transfer_learning_test,\\\n",
    "otu_columns, domain_columns = \\\n",
    "    read_df_with_transfer_learning_subset_fewerDomainFeatures( \\\n",
    "        metadata_names=['Temperature','Precipitation3Days'], \\\n",
    "        otu_filename='../../Datasets/otu_table_all_80.csv', \\\n",
    "        metadata_filename='../../Datasets/metadata_table_all_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domain_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict latent space for samples in transfer learning Walters et al. subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_transfer_learning_train = encoder.predict(data_microbioma_transfer_learning_train)\n",
    "latent_transfer_learning_test = encoder.predict(data_microbioma_transfer_learning_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build model to predict latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_tl():\n",
    "    in_layer = layers.Input(shape=(2,))\n",
    "    net = layers.Dense(64, activation='tanh')(in_layer)\n",
    "    net = layers.Dense(32, activation='tanh')(net)\n",
    "    net = layers.Dense(16, activation='tanh')(net)  \n",
    "    out_layer = layers.Dense(latent_transfer_learning_train.shape[1], activation=None)(net) # 'tanh already'\n",
    "    model = keras.Model(inputs=[in_layer], outputs=[out_layer], name='model')\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01), loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tl, model_tl = train_tl_noEnsemble(model_fn_tl,\n",
    "                            latent_transfer_learning_train,\n",
    "                            latent_transfer_learning_train,\n",
    "                            data_domain_transfer_learning_train,\n",
    "                            data_domain_transfer_learning_train,\n",
    "                            epochs=100,\n",
    "                            batch_size=16,\n",
    "                            verbose=-1)\n",
    "#print_results(result_tl)\n",
    "print(result_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test only Dense(domain->latent)\n",
    "predictions = test_model_tl_latent(model_tl, latent_transfer_learning_test, data_domain_transfer_learning_test)\n",
    "#save_predictions(predictions, 'experiment_transfer_learning_WaltersSubset_MLP_domain-latent_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain -> latent -> microbiome. Test set TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = test_model_tl_noEnsemble(model_tl, decoder, Percentage, tf.keras.layers.Softmax, otu_columns, data_microbioma_transfer_learning_test, data_domain_transfer_learning_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
